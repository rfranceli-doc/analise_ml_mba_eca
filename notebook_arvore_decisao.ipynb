{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "cells": [

  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# üå≥ √Årvore de Decis√£o ‚Äî Churn do Produto A\n",
    "**P√≥s-Gradua√ß√£o BI & Analytics ¬∑ An√°lise Complementar ao Logit**\n",
    "\n",
    "---\n",
    "\n",
    "### Por que √Årvore de Decis√£o aqui?\n",
    "\n",
    "O Logit entregou AUC ~0.83 e interpreta√ß√£o via coeficientes lineares.  \n",
    "A √°rvore de decis√£o vai mostrar **como o modelo raciocina em regras** ‚Äî a l√≥gica em forma de `if/else`.  \n",
    "Isso tem duas vantagens pr√°ticas:\n",
    "\n",
    "- **Interpretabilidade visual direta** ‚Äî qualquer pessoa de neg√≥cio consegue seguir o fluxo\n",
    "- **Captura intera√ß√µes** ‚Äî o modelo descobre que `segmento_A = 1 E nps_score < 5` √© especialmente perigoso, sem precisar que a gente especifique essa intera√ß√£o\n",
    "\n",
    "### Rela√ß√£o com os outros modelos\n",
    "\n",
    "| Modelo | Interpreta como | Captura intera√ß√µes | AUC t√≠pico |\n",
    "|---|---|---|---|\n",
    "| Logit | Coeficientes lineares | ‚ùå N√£o | 0.82‚Äì0.86 |\n",
    "| **√Årvore de Decis√£o** | **Regras if/else** | **‚úÖ Sim** | 0.80‚Äì0.88 |\n",
    "| XGBoost | SHAP values | ‚úÖ Sim (muito) | 0.87‚Äì0.92 |\n",
    "\n",
    "---\n",
    "### Roteiro\n",
    "1. Importar e preparar os dados (mesmo pr√©-processamento do Logit)\n",
    "2. Problema de profundidade: overfitting vs. underfitting\n",
    "3. Encontrar a profundidade √≥tima\n",
    "4. Treinar o modelo final\n",
    "5. Visualizar a √°rvore (interpreta√ß√£o visual)\n",
    "6. Extrair regras de decis√£o em texto\n",
    "7. Avaliar: Matriz de Confus√£o, AUC-ROC\n",
    "8. Import√¢ncia das features\n",
    "9. Comparar com Logit\n",
    "10. Sa√≠da acion√°vel: segmentos de risco com regras claras"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Imports ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve,\n",
    "    accuracy_score, f1_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 130,\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "COR_CHURN  = '#c84b2f'\n",
    "COR_OK     = '#2f6ec8'\n",
    "COR_NEUTRO = '#94a3b8'\n",
    "\n",
    "print('‚úÖ Bibliotecas carregadas')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "prep_title",
   "metadata": {},
   "source": ["## 1. Preparar os Dados"]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Carregar dados ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "URL = 'https://raw.githubusercontent.com/SEU_USUARIO/ml-bi-analytics-aula/main/data/clientes_produto_A.csv'\n",
    "# df = pd.read_csv('clientes_produto_A.csv')  # local\n",
    "df = pd.read_csv(URL)\n",
    "print(f'Shape: {df.shape}')\n",
    "\n",
    "# ‚îÄ‚îÄ Pr√©-processamento (id√™ntico ao notebook do Logit) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df_model = pd.get_dummies(\n",
    "    df.drop(columns=['id_cliente', 'segmento', 'prob_churn_real'], errors='ignore'),\n",
    "    columns=['regiao', 'porte'],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "TARGET   = 'reduziu_compras'\n",
    "X        = df_model.drop(columns=[TARGET])\n",
    "y        = df_model[TARGET]\n",
    "FEATURES = list(X.columns)\n",
    "\n",
    "# Imputar missing com mediana\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imp   = pd.DataFrame(imputer.fit_transform(X), columns=FEATURES)\n",
    "\n",
    "# Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imp, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Treino: {X_train.shape} | Teste: {X_test.shape}')\n",
    "print(f'Churn rate: {y.mean():.1%}')\n",
    "print()\n",
    "print('üìå √Årvore de decis√£o N√ÉO precisa de StandardScaler.')\n",
    "print('   O algoritmo usa thresholds ‚Äî a escala das vari√°veis √© irrelevante.')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "depth_title",
   "metadata": {},
   "source": [
    "## 2 + 3. O Problema da Profundidade\n\n",
    "> **Profundidade pequena** ‚Üí underfitting: √°rvore simplista, n√£o captura padr√µes reais.  \n",
    "> **Profundidade grande** ‚Üí overfitting: decora o treino, generaliza mal.  \n",
    "> Encontrar o ponto de equil√≠brio √© o principal hiperpar√¢metro da √°rvore."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "depth_search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Curva de complexidade: AUC treino vs. teste por profundidade ‚îÄ‚îÄ‚îÄ\n",
    "depths     = range(1, 14)\n",
    "aucs_train = []\n",
    "aucs_test  = []\n",
    "aucs_cv    = []\n",
    "\n",
    "for d in depths:\n",
    "    dt_tmp = DecisionTreeClassifier(\n",
    "        max_depth=d, random_state=42,\n",
    "        class_weight='balanced', min_samples_leaf=15\n",
    "    )\n",
    "    dt_tmp.fit(X_train, y_train)\n",
    "    aucs_train.append(roc_auc_score(y_train, dt_tmp.predict_proba(X_train)[:, 1]))\n",
    "    aucs_test.append(roc_auc_score(y_test,  dt_tmp.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "    cv = cross_val_score(\n",
    "        DecisionTreeClassifier(max_depth=d, random_state=42,\n",
    "                               class_weight='balanced', min_samples_leaf=15),\n",
    "        X_imp, y, cv=5, scoring='roc_auc'\n",
    "    )\n",
    "    aucs_cv.append(cv.mean())\n",
    "\n",
    "best_depth = list(depths)[np.argmax(aucs_cv)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4.5))\n",
    "ax.plot(depths, aucs_train, 'o-', color=COR_NEUTRO, lw=2, ms=6,\n",
    "        label='AUC ‚Äî Treino (otimista)')\n",
    "ax.plot(depths, aucs_test,  's-', color=COR_OK,    lw=2, ms=6,\n",
    "        label='AUC ‚Äî Teste')\n",
    "ax.plot(depths, aucs_cv,    '^-', color=COR_CHURN, lw=2, ms=6,\n",
    "        label='AUC ‚Äî Cross-val 5-fold (mais confi√°vel)')\n",
    "ax.axvline(best_depth, color='#1a1a1a', lw=1.5, linestyle='--',\n",
    "           label=f'Profundidade √≥tima: {best_depth}')\n",
    "ax.fill_betweenx([0.5, 1.01], best_depth - 0.4, best_depth + 0.4,\n",
    "                 alpha=0.08, color='#1a1a1a')\n",
    "ax.annotate('‚Üê Underfitting', xy=(2, aucs_cv[1]),\n",
    "            xytext=(2.4, 0.72), fontsize=8.5, color='#888')\n",
    "ax.annotate('Overfitting ‚Üí\\n(treino ‚Üë, teste ‚Üì)', xy=(10, aucs_train[9]),\n",
    "            xytext=(9.2, 0.84), fontsize=8.5, color='#888', ha='center')\n",
    "ax.set(xlabel='Profundidade m√°xima (max_depth)', ylabel='AUC-ROC',\n",
    "       title='Curva de Complexidade ‚Äî Underfitting vs. Overfitting',\n",
    "       xlim=(0.8, max(depths) + 0.2), ylim=(0.65, 1.01))\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Profundidade √≥tima (cross-val): {best_depth}')\n",
    "print(f'AUC cross-val: {aucs_cv[best_depth-1]:.3f}')\n",
    "print(f'AUC teste:     {aucs_test[best_depth-1]:.3f}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "fit_title",
   "metadata": {},
   "source": ["## 4. Treinar o Modelo Final"]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Modelo final ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth         = best_depth,\n",
    "    class_weight      = 'balanced',\n",
    "    min_samples_leaf  = 20,    # n√≥ folha precisa de pelo menos 20 amostras\n",
    "    min_samples_split = 40,    # n√≥ interno precisa de pelo menos 40 para dividir\n",
    "    random_state      = 42\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = dt.predict(X_test)\n",
    "y_proba = dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('Par√¢metros do modelo final:')\n",
    "print(f'  max_depth:           {dt.max_depth}')\n",
    "print(f'  N√≥s totais:          {dt.tree_.node_count}')\n",
    "print(f'  Folhas (segmentos):  {dt.get_n_leaves()}')\n",
    "print(f'  Features utilizadas: {(dt.feature_importances_ > 0).sum()} de {len(FEATURES)}')\n",
    "print()\n",
    "print('M√©tricas no conjunto de teste:')\n",
    "print(f'  AUC-ROC  : {roc_auc_score(y_test, y_proba):.3f}')\n",
    "print(f'  Acur√°cia : {accuracy_score(y_test, y_pred):.3f}')\n",
    "print(f'  Recall   : {recall_score(y_test, y_pred):.3f}')\n",
    "print(f'  Precis√£o : {precision_score(y_test, y_pred):.3f}')\n",
    "print(f'  F1-Score : {f1_score(y_test, y_pred):.3f}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "tree_title",
   "metadata": {},
   "source": [
    "## 5. Visualizar a √Årvore\n\n",
    "> Esta √© a principal vantagem da √°rvore de decis√£o sobre outros modelos:  \n",
    "> **qualquer pessoa de neg√≥cio consegue seguir a l√≥gica de cima para baixo.**"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tree_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Nomes leg√≠veis para os n√≥s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "nomes_legiveis = {\n",
    "    'segmento_A':            'Segmento A',\n",
    "    'var_compras_6m':        'Var. Compras 6m (%)',\n",
    "    'freq_compras_trim':     'Freq. Compras/Trim',\n",
    "    'ticket_medio_ratio':    'Ticket M√©dio Ratio',\n",
    "    'tempo_cliente_anos':    'Tempo Cliente (anos)',\n",
    "    'nps_score':             'NPS Score',\n",
    "    'canal_digital':         'Canal Digital',\n",
    "    'vendedor_rotatividade': 'Rot. Vendedor',\n",
    "    'inadimplencia_hist':    'Inadimpl√™ncia Hist.',\n",
    "}\n",
    "feature_names_plot = [nomes_legiveis.get(f, f) for f in FEATURES]\n",
    "\n",
    "# ‚îÄ‚îÄ Plotar √°rvore ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, ax = plt.subplots(figsize=(22, 9))\n",
    "plot_tree(\n",
    "    dt,\n",
    "    feature_names = feature_names_plot,\n",
    "    class_names   = ['N√£o reduziu', 'Reduziu'],\n",
    "    filled        = True,\n",
    "    rounded       = True,\n",
    "    fontsize      = 8,\n",
    "    ax            = ax,\n",
    "    impurity      = False,\n",
    "    precision     = 2,\n",
    ")\n",
    "ax.set_title(\n",
    "    '√Årvore de Decis√£o ‚Äî Churn do Produto A\\n'\n",
    "    '(azul = majoritariamente n√£o-churn  |  laranja = majoritariamente churn)',\n",
    "    fontsize=12, fontweight='bold', pad=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('üí° Como ler a √°rvore:')\n",
    "print('   ‚Ä¢ Cada n√≥ mostra a regra de divis√£o (ex: NPS ‚â§ 4.5)')\n",
    "print('   ‚Ä¢ Cor mais intensa = maior pureza do n√≥')\n",
    "print('   ‚Ä¢ Folhas laranjas = segmento de alto risco de churn')\n",
    "print('   ‚Ä¢ Folhas azuis   = segmento de baixo risco')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "rules_title",
   "metadata": {},
   "source": [
    "## 6. Regras de Decis√£o em Texto\n\n",
    "> A √°rvore pode ser exportada como regras `if/else` em linguagem natural.  \n",
    "> O time de neg√≥cio pode aplicar essas regras **sem abrir o Python**."
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rules_text",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Exportar como texto ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "regras = export_text(\n",
    "    dt,\n",
    "    feature_names = feature_names_plot,\n",
    "    decimals      = 2,\n",
    "    show_weights  = True\n",
    ")\n",
    "print('=== REGRAS DE DECIS√ÉO (formato if/else) ===')\n",
    "print(regras)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rules_leaves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Resumo das folhas: quais segmentos t√™m alto risco? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "tree_ = dt.tree_\n",
    "\n",
    "print('=== FOLHAS DA √ÅRVORE ===\\n')\n",
    "print(f\"{'Folha':>6}  {'N amostras':>10}  {'% churn':>9}  {'Classifica√ß√£o'}\")\n",
    "print('‚îÄ' * 55)\n",
    "\n",
    "for node_id in range(tree_.node_count):\n",
    "    if tree_.children_left[node_id] != -1:\n",
    "        continue  # n√£o √© folha\n",
    "    n_total   = int(tree_.n_node_samples[node_id])\n",
    "    n_class   = tree_.value[node_id][0]\n",
    "    pct_churn = n_class[1] / n_class.sum()\n",
    "    classe    = 'üî¥ ALTO RISCO' if pct_churn > 0.55 else 'üü¢ Baixo risco'\n",
    "    print(f'  {node_id:>4}  {n_total:>10,}  {pct_churn:>8.1%}  {classe}')\n",
    "\n",
    "print()\n",
    "print('üí° Cada folha √© um segmento homog√™neo.')\n",
    "print('   Folhas vermelhas ‚Üí a√ß√£o comercial priorit√°ria.')"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Em que n√≠vel cada feature aparece? ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Features no n√≠vel 0 (raiz) t√™m o maior poder discriminat√≥rio global.\n",
    "feature_depth = {}\n",
    "\n",
    "def traverse(node, depth):\n",
    "    if tree_.children_left[node] == -1:\n",
    "        return\n",
    "    fname = feature_names_plot[tree_.feature[node]]\n",
    "    feature_depth.setdefault(fname, []).append(depth)\n",
    "    traverse(tree_.children_left[node],  depth + 1)\n",
    "    traverse(tree_.children_right[node], depth + 1)\n",
    "\n",
    "traverse(0, 0)\n",
    "\n",
    "print('Features por n√≠vel da √°rvore (n√≠vel 0 = raiz = mais discriminante):\\n')\n",
    "for nivel in range(best_depth):\n",
    "    feats = [f for f, ds in feature_depth.items() if nivel in ds]\n",
    "    if feats:\n",
    "        print(f'  N√≠vel {nivel}: {\" | \".join(feats)}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "eval_title",
   "metadata": {},
   "source": ["## 7. Avalia√ß√£o ‚Äî Matriz de Confus√£o e AUC-ROC"]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ M√©tricas completas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cm  = confusion_matrix(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "\n",
    "# Matriz de confus√£o\n",
    "axes[0].imshow(cm, cmap='Blues')\n",
    "labels_cm = [['TN\\n(acertou n√£o-churn)', 'FP\\n(alarme falso)'],\n",
    "             ['FN\\n(perdeu churn)',       'TP\\n(pegou churn)']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        cor_txt = 'white' if cm[i, j] > cm.max() / 2 else '#1a1a1a'\n",
    "        axes[0].text(j, i, f'{cm[i,j]:,}\\n{labels_cm[i][j]}',\n",
    "                     ha='center', va='center', fontsize=9, color=cor_txt)\n",
    "axes[0].set(xticks=[0, 1], yticks=[0, 1],\n",
    "            xticklabels=['Previsto: N√£o', 'Previsto: Sim'],\n",
    "            yticklabels=['Real: N√£o', 'Real: Sim'],\n",
    "            title='Matriz de Confus√£o')\n",
    "\n",
    "# Curva ROC\n",
    "axes[1].plot(fpr, tpr, color=COR_CHURN, lw=2.5, label=f'√Årvore (AUC={auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], '--', color=COR_NEUTRO, lw=1)\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.07, color=COR_CHURN)\n",
    "axes[1].set(xlabel='FPR', ylabel='TPR', title='Curva ROC')\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "# Distribui√ß√£o das probabilidades por classe real\n",
    "bins = np.linspace(0, 1, 20)\n",
    "axes[2].hist(y_proba[y_test == 0], bins=bins, color=COR_OK,    alpha=0.65,\n",
    "             label='Real: N√£o reduziu', density=True)\n",
    "axes[2].hist(y_proba[y_test == 1], bins=bins, color=COR_CHURN, alpha=0.65,\n",
    "             label='Real: Reduziu', density=True)\n",
    "axes[2].axvline(0.5, color='#1a1a1a', lw=1.3, linestyle='--', label='Threshold 0.5')\n",
    "axes[2].set(xlabel='Probabilidade Prevista', ylabel='Densidade',\n",
    "            title='Distribui√ß√£o das Probabilidades')\n",
    "axes[2].legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Avalia√ß√£o ‚Äî √Årvore de Decis√£o', fontweight='bold', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['N√£o reduziu', 'Reduziu']))"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "imp_title",
   "metadata": {},
   "source": ["## 8. Import√¢ncia das Features"]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Import√¢ncia Gini ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "imp_df = pd.DataFrame({\n",
    "    'feature':    FEATURES,\n",
    "    'nome':       feature_names_plot,\n",
    "    'importance': dt.feature_importances_\n",
    "}).query('importance > 0').sort_values('importance', ascending=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, max(4, len(imp_df) * 0.42 + 1)))\n",
    "\n",
    "# Barras\n",
    "q75 = imp_df['importance'].quantile(0.75)\n",
    "cores_imp = [COR_CHURN if v >= q75 else COR_NEUTRO for v in imp_df['importance']]\n",
    "axes[0].barh(imp_df['nome'], imp_df['importance'], color=cores_imp)\n",
    "axes[0].set(title='Import√¢ncia das Features (Gini Impurity)',\n",
    "            xlabel='Import√¢ncia relativa')\n",
    "for i, v in enumerate(imp_df['importance']):\n",
    "    axes[0].text(v + 0.002, i, f'{v:.3f}', va='center', fontsize=8)\n",
    "\n",
    "# Acumulada\n",
    "imp_sorted = imp_df.sort_values('importance', ascending=False)\n",
    "cum_imp    = imp_sorted['importance'].cumsum()\n",
    "n_80       = int((cum_imp < 0.80).sum()) + 1\n",
    "\n",
    "axes[1].bar(range(len(imp_sorted)), imp_sorted['importance'],\n",
    "            color=[COR_CHURN if i < n_80 else COR_NEUTRO for i in range(len(imp_sorted))])\n",
    "ax2 = axes[1].twinx()\n",
    "ax2.plot(range(len(imp_sorted)), cum_imp.values, 'o-', color='#1a1a1a', lw=1.8, ms=5)\n",
    "ax2.axhline(0.80, color='#b07d1a', lw=1.2, linestyle='--', label='80% acumulado')\n",
    "ax2.set(ylabel='Import√¢ncia acumulada', ylim=(0, 1.05))\n",
    "ax2.legend(fontsize=8)\n",
    "axes[1].set(\n",
    "    title=f'{n_80} features explicam 80% do poder preditivo',\n",
    "    xticks=range(len(imp_sorted)), ylabel='Import√¢ncia'\n",
    ")\n",
    "axes[1].set_xticklabels(\n",
    "    [n[:14] for n in imp_sorted['nome']], rotation=40, ha='right', fontsize=8)\n",
    "\n",
    "plt.suptitle('Import√¢ncia das Features ‚Äî √Årvore de Decis√£o', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Top 5 features por import√¢ncia Gini:')\n",
    "for _, r in imp_df.sort_values('importance', ascending=False).head(5).iterrows():\n",
    "    print(f'  {r[\"nome\"]:<32} {r[\"importance\"]:.4f}')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "compare_title",
   "metadata": {},
   "source": ["## 9. Compara√ß√£o com o Logit"]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Logit (com normaliza√ß√£o ‚Äî obrigat√≥rio para ele) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "scaler       = StandardScaler()\n",
    "Xtr_sc       = scaler.fit_transform(X_train)\n",
    "Xte_sc       = scaler.transform(X_test)\n",
    "logit        = LogisticRegression(C=1.0, max_iter=500, random_state=42)\n",
    "logit.fit(Xtr_sc, y_train)\n",
    "y_proba_l    = logit.predict_proba(Xte_sc)[:, 1]\n",
    "y_pred_l     = logit.predict(Xte_sc)\n",
    "\n",
    "# ‚îÄ‚îÄ Tabela comparativa ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "metricas = [\n",
    "    ('AUC-ROC',   lambda yp, ypr: roc_auc_score(y_test, ypr)),\n",
    "    ('Acur√°cia',  lambda yp, ypr: accuracy_score(y_test, yp)),\n",
    "    ('Recall',    lambda yp, ypr: recall_score(y_test, yp)),\n",
    "    ('Precis√£o',  lambda yp, ypr: precision_score(y_test, yp)),\n",
    "    ('F1-Score',  lambda yp, ypr: f1_score(y_test, yp)),\n",
    "]\n",
    "\n",
    "print(f\"{'M√©trica':<22}  {'√Årvore':>10}  {'Logit':>10}  Melhor\")\n",
    "print('‚îÄ' * 55)\n",
    "for nome_m, fn in metricas:\n",
    "    av = fn(y_pred, y_proba)\n",
    "    lv = fn(y_pred_l, y_proba_l)\n",
    "    melhor = '‚úÖ √Årvore' if av > lv else '‚úÖ Logit'\n",
    "    print(f'  {nome_m:<20}  {av:>10.3f}  {lv:>10.3f}  {melhor}')\n",
    "\n",
    "# ‚îÄ‚îÄ Curvas ROC sobrepostas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "for nome_m, ypr, cor in [\n",
    "    ('√Årvore de Decis√£o',   y_proba,   COR_CHURN),\n",
    "    ('Regress√£o Log√≠stica', y_proba_l, COR_OK),\n",
    "]:\n",
    "    fp, tp, _ = roc_curve(y_test, ypr)\n",
    "    auc_m = roc_auc_score(y_test, ypr)\n",
    "    ax.plot(fp, tp, lw=2.5, color=cor, label=f'{nome_m} (AUC={auc_m:.3f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], '--', color=COR_NEUTRO, lw=1)\n",
    "ax.set(xlabel='FPR', ylabel='TPR', title='Curvas ROC ‚Äî Comparativo')\n",
    "ax.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('üí° Quando escolher √Årvore vs. Logit?')\n",
    "print()\n",
    "print('  √Årvore ‚Üí quando precisar explicar o modelo em reuni√£o com gestores')\n",
    "print('  √Årvore ‚Üí quando houver intera√ß√µes entre vari√°veis')\n",
    "print('  √Årvore ‚Üí quando o time de campo vai aplicar regras manualmente')\n",
    "print('  Logit  ‚Üí quando AUC for significativamente maior')\n",
    "print('  Logit  ‚Üí quando exig√™ncia regulat√≥ria pede coeficientes/p-values')\n",
    "print('  Logit  ‚Üí quando precisar calibrar threshold via EMP')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "segments_title",
   "metadata": {},
   "source": [
    "## 10. Sa√≠da Acion√°vel ‚Äî Segmentos com Regras Claras\n\n",
    "> A grande vantagem operacional da √°rvore:  \n",
    "> **cada folha vira um segmento com uma regra que o time aplica sem abrir o Python.**"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "segments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Scoring de toda a base ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "X_full = pd.DataFrame(\n",
    "    imputer.transform(\n",
    "        df_model.drop(columns=[TARGET]).reindex(columns=FEATURES, fill_value=0)\n",
    "    ),\n",
    "    columns=FEATURES\n",
    ")\n",
    "\n",
    "prob_full  = dt.predict_proba(X_full)[:, 1]\n",
    "folha_full = dt.apply(X_full)   # ID da folha para cada cliente\n",
    "\n",
    "resultado_full = pd.DataFrame({\n",
    "    'id_cliente':    df['id_cliente'],\n",
    "    'segmento_A':    df['segmento_A'],\n",
    "    'nps_score':     df['nps_score'],\n",
    "    'canal_digital': df['canal_digital'],\n",
    "    'prob_churn':    prob_full.round(4),\n",
    "    'folha_id':      folha_full,\n",
    "    'alerta':        (prob_full >= 0.5).astype(int),\n",
    "}).sort_values('prob_churn', ascending=False)\n",
    "\n",
    "# Perfil de cada folha\n",
    "resumo = resultado_full.groupby('folha_id').agg(\n",
    "    n_clientes  = ('id_cliente',    'count'),\n",
    "    prob_media  = ('prob_churn',    'mean'),\n",
    "    pct_seg_A   = ('segmento_A',    'mean'),\n",
    "    nps_medio   = ('nps_score',     'mean'),\n",
    "    pct_digital = ('canal_digital', 'mean'),\n",
    ").sort_values('prob_media', ascending=False).round(3)\n",
    "\n",
    "resumo['risco'] = resumo['prob_media'].apply(\n",
    "    lambda x: 'üî¥ ALTO' if x > 0.65 else ('üü° M√âDIO' if x > 0.35 else 'üü¢ BAIXO')\n",
    ")\n",
    "\n",
    "print('Perfil de cada segmento (folha da √°rvore):')\n",
    "print(resumo.to_string())\n",
    "\n",
    "resultado_full.to_csv('arvore_segmentos_clientes.csv', index=False)\n",
    "print('\\n‚úÖ arvore_segmentos_clientes.csv exportado')"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "segments_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Visualiza√ß√£o executiva ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Pizza: distribui√ß√£o de risco\n",
    "n_alerta = resultado_full['alerta'].sum()\n",
    "n_ok     = len(resultado_full) - n_alerta\n",
    "axes[0].pie(\n",
    "    [n_ok, n_alerta],\n",
    "    labels=[f'Baixo/m√©dio risco\\n({n_ok:,})', f'Alto risco (alerta)\\n({n_alerta:,})'],\n",
    "    colors=[COR_OK, COR_CHURN],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    explode=[0, 0.07],\n",
    "    textprops={'fontsize': 9}\n",
    ")\n",
    "axes[0].set_title('Distribui√ß√£o de Risco na Base', fontweight='bold')\n",
    "\n",
    "# Heatmap: prob churn por segmento √ó canal\n",
    "crosstab = resultado_full.groupby(\n",
    "    ['segmento_A', 'canal_digital'])['prob_churn'].mean().unstack()\n",
    "crosstab.index   = ['Seg. B/C', 'Seg. A']\n",
    "crosstab.columns = ['Tradicional', 'Digital']\n",
    "\n",
    "im = axes[1].imshow(crosstab.values, cmap='RdYlGn_r', vmin=0, vmax=1)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        val = crosstab.values[i, j]\n",
    "        axes[1].text(j, i, f'{val:.1%}', ha='center', va='center',\n",
    "                     fontsize=14, fontweight='bold',\n",
    "                     color='white' if val > 0.55 else '#1a1a1a')\n",
    "axes[1].set(\n",
    "    xticks=[0, 1], yticks=[0, 1],\n",
    "    xticklabels=crosstab.columns,\n",
    "    yticklabels=crosstab.index,\n",
    "    title='Probabilidade M√©dia de Churn\\nSegmento √ó Canal'\n",
    ")\n",
    "plt.colorbar(im, ax=axes[1], label='Prob. churn', shrink=0.75)\n",
    "\n",
    "plt.suptitle('Segmentos de Risco ‚Äî Vis√£o Executiva', fontweight='bold', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo executivo\n",
    "n_seg_A_alerta = resultado_full[\n",
    "    (resultado_full['alerta'] == 1) & (resultado_full['segmento_A'] == 1)\n",
    "].shape[0]\n",
    "prob_pior = resultado_full[\n",
    "    (resultado_full['segmento_A'] == 1) & (resultado_full['canal_digital'] == 1)\n",
    "]['prob_churn'].mean()\n",
    "\n",
    "print('=== RESUMO EXECUTIVO ===')\n",
    "print(f'Clientes em alerta:                     {n_alerta:,} ({n_alerta/len(resultado_full):.1%} da base)')\n",
    "print(f'Destes, do Segmento A:                  {n_seg_A_alerta:,} ({n_seg_A_alerta/n_alerta:.1%})')\n",
    "print(f'Prob. m√©dia ‚Äî Seg. A + Canal Digital:   {prob_pior:.1%}')\n",
    "print()\n",
    "print('Regra principal identificada pela √°rvore:')\n",
    "print('  Segmento A + Canal Digital + NPS baixo = grupo de maior risco')\n",
    "print('  ‚Üí A√ß√£o: campanha de reativa√ß√£o com oferta proporcional ao LTV previsto')"
   ]
  },

  {
   "cell_type": "markdown",
   "id": "synthesis",
   "metadata": {},
   "source": [
    "## S√≠ntese: Quando Usar Cada Modelo?\n\n",
    "| Situa√ß√£o | Modelo recomendado |\n",
    "|---|---|\n",
    "| Explicar para gestores sem Python | **√Årvore de Decis√£o** |\n",
    "| Time de campo aplica regras manualmente | **√Årvore de Decis√£o** |\n",
    "| Coeficientes/p-values para auditoria | **Logit** |\n",
    "| Calibrar threshold via EMP | **Logit** |\n",
    "| Maximizar AUC sem restri√ß√£o de interpretabilidade | **XGBoost** |\n",
    "| Detectar intera√ß√µes complexas | **XGBoost + SHAP** |\n",
    "\n",
    "---\n",
    "*A √°rvore n√£o √© melhor nem pior que o Logit ‚Äî ela responde perguntas diferentes.*  \n",
    "*Rodar os dois e comparar √© sempre uma boa pr√°tica.*"
   ]
  }

 ]
}
