{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# ğŸ—‚ï¸ K-Means â€” SegmentaÃ§Ã£o RFM de Clientes\n",
    "**PÃ³s-GraduaÃ§Ã£o BI & Analytics Â· ML Aplicado a DecisÃµes de NegÃ³cio**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¡ Sinal de NegÃ³cio\n",
    "> Taxa de abertura de campanhas caiu de **22% para 9%** em 12 meses.  \n",
    "> HipÃ³tese do marketing: estamos mandando a mesma mensagem para perfis completamente diferentes.  \n",
    "> Pergunta: **existem grupos naturais de comportamento de compra?**\n",
    "\n",
    "### ğŸ—ï¸ O que vamos construir\n",
    "SegmentaÃ§Ã£o de clientes baseada em **RFM + variaÃ§Ã£o de compras**.  \n",
    "A saÃ­da Ã© um arquivo com cluster por cliente para alimentar o CRM.\n",
    "\n",
    "---\n",
    "### Roteiro\n",
    "1. Importar e explorar a base\n",
    "2. Por que normalizar? (demonstraÃ§Ã£o visual)\n",
    "3. Encontrar o k certo (Elbow + Silhouette)\n",
    "4. Treinar o K-Means\n",
    "5. Visualizar (PCA 2D)\n",
    "6. Interpretar os clusters (centrÃ³ides)\n",
    "7. Validar e nomear\n",
    "8. Cruzar com resultados do Logit\n",
    "9. Exportar para o CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "plt.rcParams.update({'figure.dpi': 120, 'axes.spines.top': False, 'axes.spines.right': False})\n",
    "CORES_CLUSTER = ['#c84b2f', '#94a3b8', '#2a8c5a', '#7c3dc8']\n",
    "print('âœ… Bibliotecas carregadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: carregar dados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "URL = 'https://raw.githubusercontent.com/SEU_USUARIO/ml-bi-analytics-aula/main/data/rfm_clientes.csv'\n",
    "# df = pd.read_csv('rfm_clientes.csv')  # local\n",
    "df = pd.read_csv(URL)\n",
    "print(f'Shape: {df.shape}')\n",
    "print('\\nEstatÃ­sticas descritivas:')\n",
    "df.describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norm_title",
   "metadata": {},
   "source": ["## 2. Por que normalizar?\n\n> **A base foi entregue SEM normalizaÃ§Ã£o â€” propositalmente.**  \n> Antes de corrigir isso, vamos ver o que acontece com K-Means sem normalizar."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norm_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: demonstraÃ§Ã£o visual do problema â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FEATURES = ['recencia_dias','freq_compras_ano','valor_total_ano',\n",
    "            'var_compras_ano_ant','ticket_medio','num_produtos_distintos',\n",
    "            'nps_score','canal_digital']\n",
    "\n",
    "X = df[FEATURES].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "# Escalas sem normalizaÃ§Ã£o\n",
    "scales = X.std().sort_values(ascending=False)\n",
    "axes[0].barh(scales.index, scales.values, color='#c84b2f')\n",
    "axes[0].set(title='Desvio PadrÃ£o por Feature\\n(SEM normalizaÃ§Ã£o)',\n",
    "            xlabel='Desvio PadrÃ£o')\n",
    "for i, v in enumerate(scales.values):\n",
    "    axes[0].text(v + 10, i, f'{v:,.0f}', va='center', fontsize=8)\n",
    "\n",
    "# K-Means sem normalizar (demonstrar problema)\n",
    "km_raw = KMeans(n_clusters=4, random_state=42, n_init=10).fit(X)\n",
    "axes[1].scatter(X['recencia_dias'], X['valor_total_ano'],\n",
    "                c=km_raw.labels_, cmap='tab10', s=10, alpha=0.5)\n",
    "axes[1].set(title='Clusters SEM normalizaÃ§Ã£o\\n(dominados por valor_total_ano)',\n",
    "            xlabel='RecÃªncia (dias)', ylabel='Valor Total Ano (R$)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ’¡ valor_total_ano tem desvio padrÃ£o ~100Ã— maior que nps_score.')\n",
    "print('   K-Means usa distÃ¢ncia euclidiana â†’ a variÃ¡vel de maior escala domina.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norm_apply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” Aplicar StandardScaler     â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Dica: scaler = StandardScaler()\n",
    "#       X_sc = scaler.fit_transform(X)\n",
    "#       X_sc = pd.DataFrame(X_sc, columns=FEATURES)\n",
    "\n",
    "scaler = ___\n",
    "X_sc   = pd.DataFrame(___, columns=FEATURES)\n",
    "\n",
    "print('ApÃ³s normalizaÃ§Ã£o â€” mÃ©dia e desvio padrÃ£o:')\n",
    "print(X_sc.agg(['mean','std']).round(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k_title",
   "metadata": {},
   "source": ["## 3. Encontrar o k Certo"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” Loop de inÃ©rcia para o Elbow Method   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Dica: para k in range(2, 9): km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "#       inertias.append(km.fit(X_sc).inertia_)\n",
    "\n",
    "K_range  = range(2, 9)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=___, random_state=42, n_init=10)\n",
    "    km.fit(___)\n",
    "    inertias.append(___)\n",
    "    silhouettes.append(silhouette_score(X_sc, km.labels_))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'o-', color='#2f6ec8', lw=2, ms=7)\n",
    "axes[0].set(title='MÃ©todo do Cotovelo (Elbow)', xlabel='k', ylabel='InÃ©rcia')\n",
    "axes[0].axvline(4, color='#c84b2f', lw=1.5, linestyle='--', label='k=4')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(K_range, silhouettes, 'o-', color='#2a8c5a', lw=2, ms=7)\n",
    "axes[1].set(title='Silhouette Score', xlabel='k', ylabel='Score')\n",
    "axes[1].axvline(K_range[silhouettes.index(max(silhouettes))],\n",
    "                color='#c84b2f', lw=1.5, linestyle='--',\n",
    "                label=f'k Ã³timo={K_range[silhouettes.index(max(silhouettes))]}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Silhouette mÃ¡ximo: {max(silhouettes):.3f} em k={K_range[silhouettes.index(max(silhouettes))]}')\n",
    "print('\\nğŸ’¡ O cotovelo sugere k=4. Mas k=3 tambÃ©m pode ser interessante.')\n",
    "print('   A escolha final depende do que o negÃ³cio consegue operacionalizar.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fit_title",
   "metadata": {},
   "source": ["## 4. Treinar o K-Means com k=4"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "km_fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” Treinar KMeans com k=4         â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "K = 4\n",
    "km = KMeans(n_clusters=___, random_state=42, n_init=15)\n",
    "km.fit(___)\n",
    "\n",
    "df['cluster'] = km.labels_\n",
    "\n",
    "print(f'Silhouette Score (k={K}): {silhouette_score(X_sc, km.labels_):.3f}')\n",
    "print(f'Davies-Bouldin  (k={K}): {davies_bouldin_score(X_sc, km.labels_):.3f}')\n",
    "print('\\nDistribuiÃ§Ã£o dos clusters:')\n",
    "print(df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_title",
   "metadata": {},
   "source": ["## 5. Visualizar â€” PCA 2D"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pca_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” PCA 2D + scatter plot  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Dica: pca = PCA(n_components=2)\n",
    "#       X_pca = pca.fit_transform(X_sc)\n",
    "\n",
    "pca   = PCA(n_components=___)\n",
    "X_pca = pca.fit_transform(___)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "for c, cor in zip(range(K), CORES_CLUSTER):\n",
    "    mask = df['cluster'] == c\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "               color=cor, label=f'Cluster {c}', s=12, alpha=0.55)\n",
    "\n",
    "# Marcar centrÃ³ides no espaÃ§o PCA\n",
    "centroids_pca = pca.transform(km.cluster_centers_)\n",
    "ax.scatter(centroids_pca[:, 0], centroids_pca[:, 1],\n",
    "           c=CORES_CLUSTER[:K], s=200, marker='*',\n",
    "           edgecolors='black', linewidths=0.8, zorder=5, label='_nolegend_')\n",
    "\n",
    "ax.set(title=f'K-Means k={K} â€” VisualizaÃ§Ã£o PCA 2D\\n'\n",
    "             f'(variÃ¢ncia explicada: {pca.explained_variance_ratio_.sum():.1%})',\n",
    "       xlabel=f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
    "       ylabel=f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax.legend(markerscale=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('\\nğŸ’¡ PCA projeta 8 dimensÃµes em 2 para visualizaÃ§Ã£o.')\n",
    "print('   Os clusters devem aparecer razoavelmente separados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centroids_title",
   "metadata": {},
   "source": ["## 6. Interpretar os Clusters â€” CentrÃ³ides"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centroids",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” Calcular mÃ©dias por cluster       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Dica: df.groupby('cluster')[FEATURES].mean().round(2)\n",
    "\n",
    "centroides = df.groupby('cluster')[___].mean().round(2)\n",
    "print('MÃ©dias por cluster (escala original â€” antes da normalizaÃ§Ã£o):')\n",
    "centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: heatmap de centrÃ³ides normalizados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cent_sc = pd.DataFrame(km.cluster_centers_, columns=FEATURES)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 3.5))\n",
    "im = ax.imshow(cent_sc.values, cmap='RdYlGn', aspect='auto', vmin=-2.5, vmax=2.5)\n",
    "ax.set(xticks=range(len(FEATURES)), yticks=range(K),\n",
    "       xticklabels=FEATURES, yticklabels=[f'Cluster {c}' for c in range(K)])\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, ha='right', fontsize=9)\n",
    "for i in range(K):\n",
    "    for j in range(len(FEATURES)):\n",
    "        val = cent_sc.values[i, j]\n",
    "        ax.text(j, i, f'{val:.2f}', ha='center', va='center', fontsize=8,\n",
    "                color='black' if abs(val) < 1.5 else 'white')\n",
    "plt.colorbar(im, ax=ax, label='z-score', shrink=0.8)\n",
    "ax.set_title('CentrÃ³ides Normalizados â€” Verde=Alto, Vermelho=Baixo', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  COMPLETE AQUI â€” Nomear os clusters             â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Analise a tabela de centrÃ³ides acima e proponha um nome para cada cluster\n",
    "# Exemplos: 'CampeÃµes', 'Em Risco', 'Inativos', 'Novos Prometedores'\n",
    "\n",
    "NOMES_CLUSTER = {\n",
    "    0: '___',   # analise: alta/baixa recÃªncia? frequÃªncia? var_compras?\n",
    "    1: '___',\n",
    "    2: '___',\n",
    "    3: '___',\n",
    "}\n",
    "\n",
    "df['cluster_nome'] = df['cluster'].map(NOMES_CLUSTER)\n",
    "\n",
    "# Verificar concentraÃ§Ã£o de Segmento A por cluster\n",
    "print('ConcentraÃ§Ã£o do Segmento A por cluster:')\n",
    "print(df.groupby('cluster_nome')['segmento_A'].agg(['mean','sum'])\n",
    "      .rename(columns={'mean':'%_seg_A','sum':'n_seg_A'})\n",
    "      .round(3).to_string())\n",
    "print('\\nğŸ’¡ Qual cluster concentra mais o Segmento A?')\n",
    "print('   Esse cluster deve ter maior sobreposiÃ§Ã£o com os churners do Logit.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxplot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: boxplots de var_compras por cluster â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "grupos = [df[df['cluster'] == c]['var_compras_ano_ant'] for c in range(K)]\n",
    "bp = axes[0].boxplot(grupos, patch_artist=True,\n",
    "                     medianprops=dict(color='black', lw=2))\n",
    "for patch, cor in zip(bp['boxes'], CORES_CLUSTER):\n",
    "    patch.set_facecolor(cor)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[0].set(title='VariaÃ§Ã£o de Compras por Cluster',\n",
    "            xlabel='Cluster', ylabel='var_compras_ano_ant (%)')\n",
    "axes[0].axhline(0, color='#888', lw=1, linestyle='--')\n",
    "\n",
    "# ComparaÃ§Ã£o de NPS\n",
    "grupos_nps = [df[df['cluster'] == c]['nps_score'] for c in range(K)]\n",
    "bp2 = axes[1].boxplot(grupos_nps, patch_artist=True,\n",
    "                      medianprops=dict(color='black', lw=2))\n",
    "for patch, cor in zip(bp2['boxes'], CORES_CLUSTER):\n",
    "    patch.set_facecolor(cor)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1].set(title='NPS por Cluster', xlabel='Cluster', ylabel='NPS Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross_title",
   "metadata": {},
   "source": ["## 8. Cruzar com o Logit â€” ValidaÃ§Ã£o Cruzada dos Modelos"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross_logit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: cruzamento K-Means + Logit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    lista_crm = pd.read_csv('lista_risco_crm.csv')\n",
    "    cruzado   = df[['id_cliente','cluster','cluster_nome','var_compras_ano_ant']]\\\n",
    "                .merge(lista_crm[['id_cliente','prob_churn','alerta']], on='id_cliente')\n",
    "\n",
    "    print('Probabilidade mÃ©dia de churn (Logit) por cluster (K-Means):')\n",
    "    cross = cruzado.groupby('cluster_nome').agg(\n",
    "        n=('id_cliente','count'),\n",
    "        prob_churn_media=('prob_churn','mean'),\n",
    "        pct_alerta=('alerta','mean')\n",
    "    ).round(3)\n",
    "    print(cross.to_string())\n",
    "    print('\\nğŸ’¡ Clusters com alta probabilidade de churn no Logit E')\n",
    "    print('   com var_compras negativa no K-Means = mÃ¡xima prioridade.')\n",
    "except FileNotFoundError:\n",
    "    print('â„¹ï¸  Execute o notebook de Logit primeiro para o cruzamento.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_title",
   "metadata": {},
   "source": ["## 9. Exportar para o CRM"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CÃ‰LULA PRONTA: exportar segmentaÃ§Ã£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "saida_crm = df[['id_cliente','cluster','cluster_nome',\n",
    "                'var_compras_ano_ant','nps_score','segmento_A',\n",
    "                'recencia_dias','freq_compras_ano']].copy()\n",
    "saida_crm.to_csv('segmentacao_clientes.csv', index=False)\n",
    "print('âœ… segmentacao_clientes.csv exportada')\n",
    "print(f'   {len(saida_crm):,} clientes segmentados em {K} grupos')\n",
    "print('\\nDistribuiÃ§Ã£o final:')\n",
    "print(saida_crm['cluster_nome'].value_counts().to_string())\n",
    "print('\\nğŸ’¡ Cada cluster recebe uma rÃ©gua de comunicaÃ§Ã£o diferente no CRM.')\n",
    "print('   PeÃ§a ao Claude para sugerir uma estratÃ©gia para cada grupo.')"
   ]
  }
 ]
}
